package main

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"time"
)

// é€šç”¨HARæ–‡ä»¶ç»“æ„
type UniversalHARFile struct {
	Log struct {
		Version string `json:"version"`
		Creator struct {
			Name    string `json:"name"`
			Version string `json:"version"`
		} `json:"creator"`
		Browser struct {
			Name    string `json:"name"`
			Version string `json:"version"`
		} `json:"browser"`
		Pages []struct {
			StartedDateTime string `json:"startedDateTime"`
			ID              string `json:"id"`
			Title           string `json:"title"`
			PageTimings     struct {
				OnContentLoad float64 `json:"onContentLoad"`
				OnLoad        float64 `json:"onLoad"`
			} `json:"pageTimings"`
		} `json:"pages"`
		Entries []struct {
			StartedDateTime string  `json:"startedDateTime"`
			Time            float64 `json:"time"`
			Request         struct {
				Method      string `json:"method"`
				URL         string `json:"url"`
				HTTPVersion string `json:"httpVersion"`
				Headers     []struct {
					Name  string `json:"name"`
					Value string `json:"value"`
				} `json:"headers"`
				QueryString []struct {
					Name  string `json:"name"`
					Value string `json:"value"`
				} `json:"queryString"`
				PostData struct {
					MimeType string `json:"mimeType"`
					Text     string `json:"text"`
				} `json:"postData"`
				HeadersSize float64 `json:"headersSize"`
				BodySize    float64 `json:"bodySize"`
			} `json:"request"`
			Response struct {
				Status      int    `json:"status"`
				StatusText  string `json:"statusText"`
				HTTPVersion string `json:"httpVersion"`
				Headers     []struct {
					Name  string `json:"name"`
					Value string `json:"value"`
				} `json:"headers"`
				Content struct {
					Size     float64 `json:"size"`
					MimeType string  `json:"mimeType"`
					Text     string  `json:"text"`
				} `json:"content"`
				RedirectURL string  `json:"redirectURL"`
				HeadersSize float64 `json:"headersSize"`
				BodySize    float64 `json:"bodySize"`
			} `json:"response"`
			Cache struct {
				BeforeRequest interface{} `json:"beforeRequest"`
				AfterRequest  interface{} `json:"afterRequest"`
			} `json:"cache"`
			Timings struct {
				Blocked float64 `json:"blocked"`
				DNS     float64 `json:"dns"`
				Connect float64 `json:"connect"`
				Send    float64 `json:"send"`
				Wait    float64 `json:"wait"`
				Receive float64 `json:"receive"`
				SSL     float64 `json:"ssl"`
			} `json:"timings"`
		} `json:"entries"`
	} `json:"log"`
}

// é€šç”¨åˆ†æç»“æœ
type UniversalAnalysisResult struct {
	Metadata struct {
		FileName      string    `json:"fileName"`
		AnalysisTime  time.Time `json:"analysisTime"`
		TotalRequests int       `json:"totalRequests"`
		UniqueHosts   int       `json:"uniqueHosts"`
		TimeSpan      string    `json:"timeSpan"`
		BrowserInfo   string    `json:"browserInfo"`
		HARVersion    string    `json:"harVersion"`
	} `json:"metadata"`

	Hosts []HostInfo `json:"hosts"`
	APIs  []APIInfo  `json:"apis"`

	// æ•°æ®æå–ç»“æœ
	ExtractedData struct {
		Parameters    map[string]int `json:"parameters"`    // å‚æ•°ååŠå‡ºç°æ¬¡æ•°
		Headers       map[string]int `json:"headers"`       // è¯·æ±‚å¤´åŠå‡ºç°æ¬¡æ•°
		ResponseTypes map[string]int `json:"responseTypes"` // å“åº”ç±»å‹åŠå‡ºç°æ¬¡æ•°
		StatusCodes   map[string]int `json:"statusCodes"`   // çŠ¶æ€ç åŠå‡ºç°æ¬¡æ•°
		Methods       map[string]int `json:"methods"`       // HTTPæ–¹æ³•åŠå‡ºç°æ¬¡æ•°
		ContentTypes  map[string]int `json:"contentTypes"`  // å†…å®¹ç±»å‹åŠå‡ºç°æ¬¡æ•°
	} `json:"extractedData"`

	// è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç æ¨¡æ¿
	CodeTemplates struct {
		GoStructs    []string `json:"goStructs"`    // Goç»“æ„ä½“å®šä¹‰
		APIEndpoints []string `json:"apiEndpoints"` // APIç«¯ç‚¹åˆ—è¡¨
		Headers      []string `json:"headers"`      // å¸¸ç”¨è¯·æ±‚å¤´
	} `json:"codeTemplates"`
}

type HostInfo struct {
	Host         string   `json:"host"`
	RequestCount int      `json:"requestCount"`
	Methods      []string `json:"methods"`
	Paths        []string `json:"paths"`
}

type APIInfo struct {
	Method       string                 `json:"method"`
	URL          string                 `json:"url"`
	Host         string                 `json:"host"`
	Path         string                 `json:"path"`
	Parameters   map[string]interface{} `json:"parameters"`
	Headers      map[string]string      `json:"headers"`
	ResponseType string                 `json:"responseType"`
	StatusCode   int                    `json:"statusCode"`
	CallCount    int                    `json:"callCount"`
}

// é€šç”¨HARåˆ†æå™¨
type UniversalHARAnalyzer struct {
	outputDir string
}

// åˆ›å»ºæ–°çš„é€šç”¨åˆ†æå™¨
func NewUniversalHARAnalyzer() *UniversalHARAnalyzer {
	return &UniversalHARAnalyzer{
		outputDir: "universal_har_analysis",
	}
}

// æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰HARæ–‡ä»¶
func (ua *UniversalHARAnalyzer) ScanHARFiles(dir string) ([]string, error) {
	var harFiles []string

	err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if !info.IsDir() && strings.HasSuffix(strings.ToLower(info.Name()), ".har") {
			harFiles = append(harFiles, path)
		}

		return nil
	})

	return harFiles, err
}

// åˆ†æå•ä¸ªHARæ–‡ä»¶
func (ua *UniversalHARAnalyzer) AnalyzeHARFile(filePath string) (*UniversalAnalysisResult, error) {
	fmt.Printf("ğŸ“ åˆ†æHARæ–‡ä»¶: %s\n", filepath.Base(filePath))

	// è¯»å–HARæ–‡ä»¶
	data, err := os.ReadFile(filePath)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–HARæ–‡ä»¶å¤±è´¥: %w", err)
	}

	var harFile UniversalHARFile
	if err := json.Unmarshal(data, &harFile); err != nil {
		return nil, fmt.Errorf("è§£æHARæ–‡ä»¶å¤±è´¥: %w", err)
	}

	// åˆå§‹åŒ–åˆ†æç»“æœ
	result := &UniversalAnalysisResult{}
	result.Metadata.FileName = filepath.Base(filePath)
	result.Metadata.AnalysisTime = time.Now()
	result.Metadata.TotalRequests = len(harFile.Log.Entries)
	result.Metadata.HARVersion = harFile.Log.Version
	result.Metadata.BrowserInfo = fmt.Sprintf("%s %s", harFile.Log.Browser.Name, harFile.Log.Browser.Version)

	// åˆå§‹åŒ–æ•°æ®ç»Ÿè®¡
	result.ExtractedData.Parameters = make(map[string]int)
	result.ExtractedData.Headers = make(map[string]int)
	result.ExtractedData.ResponseTypes = make(map[string]int)
	result.ExtractedData.StatusCodes = make(map[string]int)
	result.ExtractedData.Methods = make(map[string]int)
	result.ExtractedData.ContentTypes = make(map[string]int)

	hostMap := make(map[string]*HostInfo)
	apiMap := make(map[string]*APIInfo)

	// åˆ†ææ¯ä¸ªè¯·æ±‚
	var startTime, endTime time.Time
	for i, entry := range harFile.Log.Entries {
		// è§£ææ—¶é—´
		if entryTime, err := time.Parse(time.RFC3339, entry.StartedDateTime); err == nil {
			if i == 0 || entryTime.Before(startTime) {
				startTime = entryTime
			}
			if i == 0 || entryTime.After(endTime) {
				endTime = entryTime
			}
		}

		// è§£æURL
		url := entry.Request.URL
		method := entry.Request.Method

		// æå–ä¸»æœºä¿¡æ¯
		if host := ua.extractHost(url); host != "" {
			if _, exists := hostMap[host]; !exists {
				hostMap[host] = &HostInfo{
					Host:    host,
					Methods: []string{},
					Paths:   []string{},
				}
			}
			hostMap[host].RequestCount++
			ua.addUniqueString(&hostMap[host].Methods, method)
			ua.addUniqueString(&hostMap[host].Paths, ua.extractPath(url))
		}

		// ç»Ÿè®¡HTTPæ–¹æ³•
		result.ExtractedData.Methods[method]++

		// ç»Ÿè®¡çŠ¶æ€ç 
		statusCode := fmt.Sprintf("%d", entry.Response.Status)
		result.ExtractedData.StatusCodes[statusCode]++

		// åˆ†æè¯·æ±‚å¤´
		for _, header := range entry.Request.Headers {
			result.ExtractedData.Headers[header.Name]++
		}

		// åˆ†ææŸ¥è¯¢å‚æ•°
		for _, param := range entry.Request.QueryString {
			result.ExtractedData.Parameters[param.Name]++
		}

		// åˆ†æPOSTæ•°æ®ä¸­çš„å‚æ•°
		if entry.Request.PostData.Text != "" {
			ua.extractPostParameters(entry.Request.PostData.Text, result.ExtractedData.Parameters)
		}

		// åˆ†æå“åº”ç±»å‹
		contentType := entry.Response.Content.MimeType
		if contentType != "" {
			result.ExtractedData.ContentTypes[contentType]++
			result.ExtractedData.ResponseTypes[ua.simplifyContentType(contentType)]++
		}

		// åˆ›å»ºAPIä¿¡æ¯
		apiKey := fmt.Sprintf("%s %s", method, ua.extractPath(url))
		if _, exists := apiMap[apiKey]; !exists {
			apiMap[apiKey] = &APIInfo{
				Method:       method,
				URL:          url,
				Host:         ua.extractHost(url),
				Path:         ua.extractPath(url),
				Parameters:   make(map[string]interface{}),
				Headers:      make(map[string]string),
				ResponseType: ua.simplifyContentType(contentType),
				StatusCode:   entry.Response.Status,
				CallCount:    0,
			}

			// æ”¶é›†å‚æ•°
			for _, param := range entry.Request.QueryString {
				apiMap[apiKey].Parameters[param.Name] = param.Value
			}

			// æ”¶é›†é‡è¦è¯·æ±‚å¤´
			for _, header := range entry.Request.Headers {
				if ua.isImportantHeader(header.Name) {
					apiMap[apiKey].Headers[header.Name] = header.Value
				}
			}
		}
		apiMap[apiKey].CallCount++
	}

	// è½¬æ¢mapä¸ºslice
	for _, host := range hostMap {
		result.Hosts = append(result.Hosts, *host)
	}
	for _, api := range apiMap {
		result.APIs = append(result.APIs, *api)
	}

	// æ’åº
	sort.Slice(result.Hosts, func(i, j int) bool {
		return result.Hosts[i].RequestCount > result.Hosts[j].RequestCount
	})
	sort.Slice(result.APIs, func(i, j int) bool {
		return result.APIs[i].CallCount > result.APIs[j].CallCount
	})

	// è®¾ç½®æ—¶é—´è·¨åº¦
	result.Metadata.UniqueHosts = len(hostMap)
	if !startTime.IsZero() && !endTime.IsZero() {
		result.Metadata.TimeSpan = fmt.Sprintf("%s - %s (%.1fåˆ†é’Ÿ)",
			startTime.Format("15:04:05"),
			endTime.Format("15:04:05"),
			endTime.Sub(startTime).Minutes())
	}

	// ç”Ÿæˆä»£ç æ¨¡æ¿
	ua.generateCodeTemplates(result)

	return result, nil
}

// æå–ä¸»æœºå
func (ua *UniversalHARAnalyzer) extractHost(url string) string {
	re := regexp.MustCompile(`https?://([^/]+)`)
	matches := re.FindStringSubmatch(url)
	if len(matches) > 1 {
		return matches[1]
	}
	return ""
}

// æå–è·¯å¾„
func (ua *UniversalHARAnalyzer) extractPath(url string) string {
	re := regexp.MustCompile(`https?://[^/]+(/[^?#]*)`)
	matches := re.FindStringSubmatch(url)
	if len(matches) > 1 {
		return matches[1]
	}
	return "/"
}

// æ·»åŠ å”¯ä¸€å­—ç¬¦ä¸²åˆ°åˆ‡ç‰‡
func (ua *UniversalHARAnalyzer) addUniqueString(slice *[]string, str string) {
	for _, existing := range *slice {
		if existing == str {
			return
		}
	}
	*slice = append(*slice, str)
}

// æå–POSTå‚æ•°
func (ua *UniversalHARAnalyzer) extractPostParameters(postData string, params map[string]int) {
	// å°è¯•è§£æJSON
	var jsonData map[string]interface{}
	if err := json.Unmarshal([]byte(postData), &jsonData); err == nil {
		ua.extractJSONKeys(jsonData, "", params)
		return
	}

	// å°è¯•è§£æè¡¨å•æ•°æ®
	if strings.Contains(postData, "=") && strings.Contains(postData, "&") {
		pairs := strings.Split(postData, "&")
		for _, pair := range pairs {
			if kv := strings.SplitN(pair, "=", 2); len(kv) == 2 {
				params[kv[0]]++
			}
		}
	}
}

// é€’å½’æå–JSONé”®
func (ua *UniversalHARAnalyzer) extractJSONKeys(data interface{}, prefix string, params map[string]int) {
	switch v := data.(type) {
	case map[string]interface{}:
		for key, value := range v {
			fullKey := key
			if prefix != "" {
				fullKey = prefix + "." + key
			}
			params[fullKey]++
			ua.extractJSONKeys(value, fullKey, params)
		}
	case []interface{}:
		for i, item := range v {
			indexKey := fmt.Sprintf("%s[%d]", prefix, i)
			ua.extractJSONKeys(item, indexKey, params)
		}
	}
}

// ç®€åŒ–å†…å®¹ç±»å‹
func (ua *UniversalHARAnalyzer) simplifyContentType(contentType string) string {
	if strings.Contains(contentType, "json") {
		return "JSON"
	}
	if strings.Contains(contentType, "html") {
		return "HTML"
	}
	if strings.Contains(contentType, "xml") {
		return "XML"
	}
	if strings.Contains(contentType, "javascript") {
		return "JavaScript"
	}
	if strings.Contains(contentType, "css") {
		return "CSS"
	}
	if strings.Contains(contentType, "image") {
		return "Image"
	}
	if strings.Contains(contentType, "text") {
		return "Text"
	}
	return "Other"
}

// åˆ¤æ–­æ˜¯å¦ä¸ºé‡è¦è¯·æ±‚å¤´
func (ua *UniversalHARAnalyzer) isImportantHeader(headerName string) bool {
	important := []string{
		"authorization", "cookie", "content-type", "accept",
		"user-agent", "referer", "origin", "x-requested-with",
		"x-csrf-token", "x-api-key", "bearer", "token",
	}

	headerLower := strings.ToLower(headerName)
	for _, imp := range important {
		if strings.Contains(headerLower, imp) {
			return true
		}
	}
	return false
}

// ç”Ÿæˆä»£ç æ¨¡æ¿
func (ua *UniversalHARAnalyzer) generateCodeTemplates(result *UniversalAnalysisResult) {
	// ç”ŸæˆGoç»“æ„ä½“
	result.CodeTemplates.GoStructs = ua.generateGoStructs(result)

	// ç”ŸæˆAPIç«¯ç‚¹åˆ—è¡¨
	result.CodeTemplates.APIEndpoints = ua.generateAPIEndpoints(result)

	// ç”Ÿæˆå¸¸ç”¨è¯·æ±‚å¤´
	result.CodeTemplates.Headers = ua.generateCommonHeaders(result)
}

// ç”ŸæˆGoç»“æ„ä½“
func (ua *UniversalHARAnalyzer) generateGoStructs(result *UniversalAnalysisResult) []string {
	var structs []string

	// åŸºç¡€å“åº”ç»“æ„ä½“
	structs = append(structs, `type APIResponse struct {
	Code    int         `+"`json:\"code\"`"+`
	Message string      `+"`json:\"message\"`"+`
	Data    interface{} `+"`json:\"data\"`"+`
}`)

	// åˆ†é¡µå“åº”ç»“æ„ä½“
	structs = append(structs, `type PagedResponse struct {
	Content       []interface{} `+"`json:\"content\"`"+`
	TotalElements int           `+"`json:\"totalElements\"`"+`
	TotalPages    int           `+"`json:\"totalPages\"`"+`
	Size          int           `+"`json:\"size\"`"+`
	Number        int           `+"`json:\"number\"`"+`
}`)

	return structs
}

// ç”ŸæˆAPIç«¯ç‚¹åˆ—è¡¨
func (ua *UniversalHARAnalyzer) generateAPIEndpoints(result *UniversalAnalysisResult) []string {
	var endpoints []string

	for _, api := range result.APIs {
		if api.CallCount > 1 { // åªåŒ…å«è°ƒç”¨æ¬¡æ•°å¤§äº1çš„API
			endpoint := fmt.Sprintf("// %s %s (è°ƒç”¨%dæ¬¡)", api.Method, api.Path, api.CallCount)
			endpoints = append(endpoints, endpoint)
		}
	}

	return endpoints
}

// ç”Ÿæˆå¸¸ç”¨è¯·æ±‚å¤´
func (ua *UniversalHARAnalyzer) generateCommonHeaders(result *UniversalAnalysisResult) []string {
	var headers []string

	// æŒ‰å‡ºç°é¢‘ç‡æ’åº
	type headerCount struct {
		name  string
		count int
	}

	var headerCounts []headerCount
	for name, count := range result.ExtractedData.Headers {
		if count > 1 && ua.isImportantHeader(name) {
			headerCounts = append(headerCounts, headerCount{name, count})
		}
	}

	sort.Slice(headerCounts, func(i, j int) bool {
		return headerCounts[i].count > headerCounts[j].count
	})

	for _, hc := range headerCounts {
		headers = append(headers, fmt.Sprintf("req.Header.Set(\"%s\", \"your_value_here\") // å‡ºç°%dæ¬¡", hc.name, hc.count))
	}

	return headers
}

// æ‰¹é‡åˆ†ææ‰€æœ‰HARæ–‡ä»¶
func (ua *UniversalHARAnalyzer) AnalyzeAllHARFiles(dir string) error {
	// åˆ›å»ºè¾“å‡ºç›®å½•
	if err := os.MkdirAll(ua.outputDir, 0755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %w", err)
	}

	// æ‰«æHARæ–‡ä»¶
	harFiles, err := ua.ScanHARFiles(dir)
	if err != nil {
		return fmt.Errorf("æ‰«æHARæ–‡ä»¶å¤±è´¥: %w", err)
	}

	if len(harFiles) == 0 {
		fmt.Println("âŒ æœªæ‰¾åˆ°HARæ–‡ä»¶")
		return nil
	}

	fmt.Printf("ğŸ” å‘ç° %d ä¸ªHARæ–‡ä»¶\n", len(harFiles))

	// åˆ†ææ¯ä¸ªæ–‡ä»¶
	for i, filePath := range harFiles {
		fmt.Printf("\n[%d/%d] ", i+1, len(harFiles))

		result, err := ua.AnalyzeHARFile(filePath)
		if err != nil {
			fmt.Printf("âŒ åˆ†æå¤±è´¥: %v\n", err)
			continue
		}

		// ä¿å­˜åˆ†æç»“æœ
		if err := ua.saveAnalysisResult(result); err != nil {
			fmt.Printf("âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: %v\n", err)
		} else {
			fmt.Printf("âœ… åˆ†æå®Œæˆ: %dä¸ªè¯·æ±‚, %dä¸ªä¸»æœº, %dä¸ªAPI\n",
				result.Metadata.TotalRequests,
				result.Metadata.UniqueHosts,
				len(result.APIs))
		}
	}

	// ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
	if err := ua.generateSummaryReport(harFiles); err != nil {
		fmt.Printf("âš ï¸ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: %v\n", err)
	}

	fmt.Printf("\nğŸ‰ åˆ†æå®Œæˆ! ç»“æœä¿å­˜åœ¨: %s\n", ua.outputDir)
	return nil
}

// ä¿å­˜åˆ†æç»“æœ
func (ua *UniversalHARAnalyzer) saveAnalysisResult(result *UniversalAnalysisResult) error {
	timestamp := time.Now().Unix()

	// ä¿å­˜JSONç»“æœ
	jsonData, err := json.MarshalIndent(result, "", "  ")
	if err != nil {
		return err
	}

	jsonFile := filepath.Join(ua.outputDir, fmt.Sprintf("%s_analysis_%d.json",
		strings.TrimSuffix(result.Metadata.FileName, ".har"), timestamp))

	if err := os.WriteFile(jsonFile, jsonData, 0644); err != nil {
		return err
	}

	// ç”ŸæˆMarkdownæŠ¥å‘Š
	if err := ua.generateMarkdownReport(result, timestamp); err != nil {
		return err
	}

	return nil
}

// ç”ŸæˆMarkdownæŠ¥å‘Š
func (ua *UniversalHARAnalyzer) generateMarkdownReport(result *UniversalAnalysisResult, timestamp int64) error {
	var report strings.Builder

	report.WriteString(fmt.Sprintf("# HARåˆ†ææŠ¥å‘Š: %s\n\n", result.Metadata.FileName))
	report.WriteString(fmt.Sprintf("**åˆ†ææ—¶é—´**: %s\n\n", result.Metadata.AnalysisTime.Format("2006-01-02 15:04:05")))

	// åŸºæœ¬ä¿¡æ¯
	report.WriteString("## ğŸ“Š åŸºæœ¬ä¿¡æ¯\n\n")
	report.WriteString(fmt.Sprintf("- **æ€»è¯·æ±‚æ•°**: %d\n", result.Metadata.TotalRequests))
	report.WriteString(fmt.Sprintf("- **å”¯ä¸€ä¸»æœºæ•°**: %d\n", result.Metadata.UniqueHosts))
	report.WriteString(fmt.Sprintf("- **æ—¶é—´è·¨åº¦**: %s\n", result.Metadata.TimeSpan))
	report.WriteString(fmt.Sprintf("- **æµè§ˆå™¨**: %s\n", result.Metadata.BrowserInfo))
	report.WriteString(fmt.Sprintf("- **HARç‰ˆæœ¬**: %s\n\n", result.Metadata.HARVersion))

	// ä¸»æœºç»Ÿè®¡
	report.WriteString("## ğŸŒ ä¸»æœºç»Ÿè®¡\n\n")
	report.WriteString("| ä¸»æœº | è¯·æ±‚æ•° | HTTPæ–¹æ³• |\n")
	report.WriteString("|------|--------|----------|\n")
	for _, host := range result.Hosts {
		methods := strings.Join(host.Methods, ", ")
		report.WriteString(fmt.Sprintf("| %s | %d | %s |\n", host.Host, host.RequestCount, methods))
	}
	report.WriteString("\n")

	// APIç»Ÿè®¡
	report.WriteString("## ğŸ”— çƒ­é—¨API (è°ƒç”¨æ¬¡æ•° > 1)\n\n")
	report.WriteString("| æ–¹æ³• | è·¯å¾„ | ä¸»æœº | è°ƒç”¨æ¬¡æ•° | å“åº”ç±»å‹ |\n")
	report.WriteString("|------|------|------|----------|----------|\n")
	for _, api := range result.APIs {
		if api.CallCount > 1 {
			report.WriteString(fmt.Sprintf("| %s | %s | %s | %d | %s |\n",
				api.Method, api.Path, api.Host, api.CallCount, api.ResponseType))
		}
	}
	report.WriteString("\n")

	// å‚æ•°ç»Ÿè®¡
	report.WriteString("## ğŸ“ å¸¸ç”¨å‚æ•° (å‡ºç°æ¬¡æ•° > 1)\n\n")
	ua.writeTopItems(&report, result.ExtractedData.Parameters, "å‚æ•°å", "å‡ºç°æ¬¡æ•°")

	// è¯·æ±‚å¤´ç»Ÿè®¡
	report.WriteString("## ğŸ“‹ å¸¸ç”¨è¯·æ±‚å¤´ (å‡ºç°æ¬¡æ•° > 5)\n\n")
	ua.writeTopItemsFiltered(&report, result.ExtractedData.Headers, "è¯·æ±‚å¤´", "å‡ºç°æ¬¡æ•°", 5)

	// HTTPæ–¹æ³•ç»Ÿè®¡
	report.WriteString("## ğŸ”§ HTTPæ–¹æ³•ç»Ÿè®¡\n\n")
	ua.writeTopItems(&report, result.ExtractedData.Methods, "æ–¹æ³•", "ä½¿ç”¨æ¬¡æ•°")

	// çŠ¶æ€ç ç»Ÿè®¡
	report.WriteString("## ğŸ“ˆ çŠ¶æ€ç ç»Ÿè®¡\n\n")
	ua.writeTopItems(&report, result.ExtractedData.StatusCodes, "çŠ¶æ€ç ", "å‡ºç°æ¬¡æ•°")

	// å“åº”ç±»å‹ç»Ÿè®¡
	report.WriteString("## ğŸ“„ å“åº”ç±»å‹ç»Ÿè®¡\n\n")
	ua.writeTopItems(&report, result.ExtractedData.ResponseTypes, "ç±»å‹", "å‡ºç°æ¬¡æ•°")

	// ä»£ç æ¨¡æ¿
	report.WriteString("## ğŸ’» ä»£ç æ¨¡æ¿\n\n")

	report.WriteString("### Goç»“æ„ä½“\n\n")
	for _, goStruct := range result.CodeTemplates.GoStructs {
		report.WriteString("```go\n")
		report.WriteString(goStruct)
		report.WriteString("\n```\n\n")
	}

	report.WriteString("### å¸¸ç”¨è¯·æ±‚å¤´è®¾ç½®\n\n")
	report.WriteString("```go\n")
	for _, header := range result.CodeTemplates.Headers {
		report.WriteString(header + "\n")
	}
	report.WriteString("```\n\n")

	report.WriteString("### APIç«¯ç‚¹åˆ—è¡¨\n\n")
	report.WriteString("```go\n")
	for _, endpoint := range result.CodeTemplates.APIEndpoints {
		report.WriteString(endpoint + "\n")
	}
	report.WriteString("```\n\n")

	// ä¿å­˜æŠ¥å‘Š
	reportFile := filepath.Join(ua.outputDir, fmt.Sprintf("%s_report_%d.md",
		strings.TrimSuffix(result.Metadata.FileName, ".har"), timestamp))

	return os.WriteFile(reportFile, []byte(report.String()), 0644)
}

// å†™å…¥æ’åºåçš„ç»Ÿè®¡é¡¹
func (ua *UniversalHARAnalyzer) writeTopItems(report *strings.Builder, items map[string]int, nameHeader, countHeader string) {
	ua.writeTopItemsFiltered(report, items, nameHeader, countHeader, 1)
}

// å†™å…¥è¿‡æ»¤åçš„æ’åºç»Ÿè®¡é¡¹
func (ua *UniversalHARAnalyzer) writeTopItemsFiltered(report *strings.Builder, items map[string]int, nameHeader, countHeader string, minCount int) {
	type item struct {
		name  string
		count int
	}

	var sortedItems []item
	for name, count := range items {
		if count > minCount {
			sortedItems = append(sortedItems, item{name, count})
		}
	}

	sort.Slice(sortedItems, func(i, j int) bool {
		return sortedItems[i].count > sortedItems[j].count
	})

	if len(sortedItems) == 0 {
		report.WriteString("æ— æ•°æ®\n\n")
		return
	}

	report.WriteString(fmt.Sprintf("| %s | %s |\n", nameHeader, countHeader))
	report.WriteString("|------|------|\n")

	maxItems := 20 // æœ€å¤šæ˜¾ç¤º20é¡¹
	for i, item := range sortedItems {
		if i >= maxItems {
			report.WriteString(fmt.Sprintf("| ... | ... |\n"))
			report.WriteString(fmt.Sprintf("| **æ€»è®¡**: %dé¡¹ | |\n", len(sortedItems)))
			break
		}
		report.WriteString(fmt.Sprintf("| %s | %d |\n", item.name, item.count))
	}
	report.WriteString("\n")
}

// ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
func (ua *UniversalHARAnalyzer) generateSummaryReport(harFiles []string) error {
	var summary strings.Builder

	summary.WriteString("# é€šç”¨HARåˆ†ææ±‡æ€»æŠ¥å‘Š\n\n")
	summary.WriteString(fmt.Sprintf("**ç”Ÿæˆæ—¶é—´**: %s\n\n", time.Now().Format("2006-01-02 15:04:05")))
	summary.WriteString(fmt.Sprintf("**åˆ†ææ–‡ä»¶æ•°**: %d\n\n", len(harFiles)))

	summary.WriteString("## ğŸ“ åˆ†æçš„æ–‡ä»¶åˆ—è¡¨\n\n")
	for i, file := range harFiles {
		summary.WriteString(fmt.Sprintf("%d. %s\n", i+1, filepath.Base(file)))
	}
	summary.WriteString("\n")

	summary.WriteString("## ğŸ“‹ ä½¿ç”¨è¯´æ˜\n\n")
	summary.WriteString("1. æ¯ä¸ªHARæ–‡ä»¶éƒ½ç”Ÿæˆäº†å¯¹åº”çš„JSONåˆ†æç»“æœå’ŒMarkdownæŠ¥å‘Š\n")
	summary.WriteString("2. JSONæ–‡ä»¶åŒ…å«å®Œæ•´çš„ç»“æ„åŒ–æ•°æ®ï¼Œå¯ç”¨äºç¨‹åºå¤„ç†\n")
	summary.WriteString("3. MarkdownæŠ¥å‘Šæä¾›äººç±»å¯è¯»çš„åˆ†æç»“æœ\n")
	summary.WriteString("4. ä»£ç æ¨¡æ¿å¯ä»¥ç›´æ¥å¤åˆ¶ä½¿ç”¨\n\n")

	summary.WriteString("## ğŸ”§ ç”Ÿæˆçš„æ–‡ä»¶è¯´æ˜\n\n")
	summary.WriteString("- `*_analysis_*.json`: ç»“æ„åŒ–åˆ†ææ•°æ®\n")
	summary.WriteString("- `*_report_*.md`: å¯è¯»æ€§åˆ†ææŠ¥å‘Š\n")
	summary.WriteString("- `summary_report.md`: æœ¬æ±‡æ€»æŠ¥å‘Š\n\n")

	summaryFile := filepath.Join(ua.outputDir, "summary_report.md")
	return os.WriteFile(summaryFile, []byte(summary.String()), 0644)
}

func main() {
	fmt.Println("ğŸš€ é€šç”¨HARåˆ†æå™¨å¯åŠ¨")
	fmt.Println("====================")

	analyzer := NewUniversalHARAnalyzer()

	// åˆ†æå½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰HARæ–‡ä»¶
	currentDir, _ := os.Getwd()

	if err := analyzer.AnalyzeAllHARFiles(currentDir); err != nil {
		fmt.Printf("âŒ åˆ†æå¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	fmt.Println("\nğŸ¯ åˆ†æå®Œæˆ!")
	fmt.Printf("ğŸ“‚ æŸ¥çœ‹ç»“æœ: %s\n", analyzer.outputDir)
}
